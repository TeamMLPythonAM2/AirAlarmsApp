{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "from app.config.configuration import Config\n",
    "from app.core.scrapers.telegram import consts\n",
    "import os\n",
    "import re\n",
    "import stanza\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv(os.path.join(Config.FILES_PATH, 'full_telegram_data.csv'), encoding='utf-8')",
   "id": "96da9731d5ad33e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['date'] = pd.to_datetime(df['date'], utc=True).dt.tz_convert('Europe/Kiev').dt.tz_localize(None)\n",
    "df['date'] = df['date'].apply(lambda x: x.replace(minute=0, second=0))\n",
    "df['lang'] = df['channel_id'].map(consts.CHANNEL_IDS)"
   ],
   "id": "ff8e8d1cc0f14771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=['id']).sort_values(by=['date'])",
   "id": "1833be9b8f022493",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv('full_telegram_data.csv')",
   "id": "58a83db4d4f9ecfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"[^\\sА-Яа-яЁёЇїІіЄєҐґ\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "df['cleaned_content'] = df['content'].apply(clean_text)"
   ],
   "id": "154eaec8cc226553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop('channel_id', axis=1)\n",
    "df = df.drop('id', axis=1)\n",
    "df = df.drop('content', axis=1)"
   ],
   "id": "707af73d4218a24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stanza.download('uk', verbose=False)\n",
    "stanza.download('ru', verbose=False)"
   ],
   "id": "7225a3ae643f25e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nlp_uk = stanza.Pipeline('uk', processors='tokenize,mwt,pos,lemma', use_gpu=False)\n",
    "nlp_ru = stanza.Pipeline('ru', processors='tokenize,pos,lemma', use_gpu=False)"
   ],
   "id": "bf16fd794a565a15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nltk.download('stopwords')",
   "id": "95753fce604654e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_stopwords(stopword_list):\n",
    "    cleaned = []\n",
    "    for word in stopword_list:\n",
    "        word = re.sub(r\"[^\\sА-Яа-яЁёЇїІіЄєҐґ]\", \"\", word)\n",
    "        word = word.strip().lower().split()\n",
    "        cleaned.extend(word)\n",
    "    return cleaned\n",
    "\n",
    "ru_stopwords = clean_stopwords(stopwords.words('russian'))\n",
    "stopwords_ua = pd.read_csv(os.path.join(Config.FILES_PATH, 'stopwords_ua.txt'), header=None, names=['stopwords'])\n",
    "uk_stopwords = clean_stopwords(list(stopwords_ua.stopwords))\n",
    "all_stopwords = set(uk_stopwords + ru_stopwords)"
   ],
   "id": "9aeb2d0bea7f6a8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def lemmatize_stanza(text, lang):\n",
    "    nlp = nlp_uk if lang == 'uk' else nlp_ru\n",
    "    doc = nlp(text)\n",
    "    return [w.lemma for sent in doc.sentences for w in sent.words]"
   ],
   "id": "e950a8c9c20310c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "496a8a2e3564c43b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['content'] = df['cleaned_content'].str.split().apply(lambda words: ' '.join(word for word in words if word.isalpha() and word not in all_stopwords))",
   "id": "adcef0400b747a33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.drop('cleaned_content', axis=1)\n",
    "df.head()"
   ],
   "id": "1f7843a1fb1b65c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_lemmatizer():\n",
    "    cache = defaultdict(dict)\n",
    "\n",
    "    def lemmatize_word(word, lang):\n",
    "        if word in cache[lang]:\n",
    "            return cache[lang][word]\n",
    "        lemmas = lemmatize_stanza(word, lang)\n",
    "        lemma = lemmas[0] if lemmas else word\n",
    "        cache[lang][word] = lemma\n",
    "        return lemma\n",
    "\n",
    "    return lemmatize_word\n",
    "\n",
    "lemmatize_word = build_lemmatizer()\n",
    "\n",
    "unique_pairs = set()\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    words = row['content'].split()\n",
    "    lang = row['lang']\n",
    "    unique_pairs.update((word, lang) for word in words)\n",
    "\n",
    "lemma_dict = {}\n",
    "for word, lang in tqdm(unique_pairs, desc=\"Lemmatizing\"):\n",
    "    lemma = lemmatize_word(word, lang)\n",
    "    lemma_dict[(word, lang)] = lemma\n",
    "\n",
    "def lemmatize_text(text, lang):\n",
    "    return ' '.join(lemma_dict.get((word, lang), word) for word in text.split())\n",
    "\n",
    "df['l_content'] = df.apply(lambda row: lemmatize_text(row['content'], row['lang']), axis=1)"
   ],
   "id": "ceae51b6cf51b4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "e8acbd9d2f5985b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
